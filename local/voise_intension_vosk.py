#!/usr/bin/env python3
# -*- coding: utf-8 -*-
import json
import os
import sys
import time
import queue
import random
import requests
import pyaudio
from vosk import Model, KaldiRecognizer
from typing import Dict, Optional

try:
    from rapidfuzz import process, fuzz
except ImportError:
    print("–û—à–∏–±–∫–∞: pip install rapidfuzz")
    sys.exit(1)

MEDIA_PLAYER_URL = "http://127.0.0.1:5000/webhook"
current_dir = os.path.dirname(os.path.abspath(__file__))
MODEL_PATH = os.path.join(current_dir, "model")
QUOTES_RU = ["–†–∏—Å–∫ ‚Äî –¥–µ–ª–æ –±–ª–∞–≥–æ—Ä–æ–¥–Ω–æ–µ.", "–£—Å–ø–µ—Ö ‚Äî —ç—Ç–æ –ø—É—Ç—å –æ—Ç –Ω–µ—É–¥–∞—á–∏ –∫ –Ω–µ—É–¥–∞—á–µ."]
FACTS_RUSSIAN = ["–ú–æ—Å–∫–≤–∞ –æ—Å–Ω–æ–≤–∞–Ω–∞ –≤ 1147 –≥–æ–¥—É.", "–ë–∞–π–∫–∞–ª ‚Äî —Å–∞–º–æ–µ –≥–ª—É–±–æ–∫–æ–µ –æ–∑–µ—Ä–æ."]

class CommandAnalyzer:
    def __init__(self, intents_map: dict, threshold=70):
        self.intents_map = intents_map
        self.threshold = threshold
        self.corpus = []
        for intent_key, data in self.intents_map.items():
            for phrase in data['phrases']:
                self.corpus.append({'phrase': phrase, 'intent': intent_key})

    def analyze(self, text: str) -> Optional[dict]:
        if not text: return None
        results = []
        for item in self.corpus:
            score = fuzz.WRatio(text, item['phrase'])
            results.append({'intent': item['intent'], 'score': score})
        
        results.sort(key=lambda x: x['score'], reverse=True)
        if results and results[0]['score'] >= self.threshold:
            return results[0]
        return None

class InfoAssistant:
    def __init__(self):
        self.running = True
        self.intents = self._setup_intents()
        self.analyzer = CommandAnalyzer(self.intents, threshold=65)
        
        if not os.path.exists(MODEL_PATH):
            print(f"‚ùå –û–®–ò–ë–ö–ê: –ù–µ—Ç –ø–∞–ø–∫–∏ model")
            sys.exit(1)
            
        print("‚è≥ –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏...")
        try:
            self.model = Model(MODEL_PATH)
            self.recognizer = KaldiRecognizer(self.model, 16000)
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –º–æ–¥–µ–ª–∏: {e}")
            sys.exit(1)
        print("‚úÖ –ì–æ—Ç–æ–≤ –∫ —Ä–∞–±–æ—Ç–µ.")

    def _setup_intents(self) -> Dict:
        return {
            'media_img_1': {
                'func': lambda: self.cmd_send_media("1", "off"),
                'phrases': ['–ø–æ–∫–∞–∂–∏ –ø–µ—Ä–≤—É—é –∫–∞—Ä—Ç–∏–Ω–∫—É', '–∫–∞—Ä—Ç–∏–Ω–∫–∞ –æ–¥–∏–Ω', '—Å–ª–∞–π–¥ 1', '–ø–µ—Ä–≤—ã–π']
            },
            'media_img_2': {
                'func': lambda: self.cmd_send_media("2", "off"),
                'phrases': ['–ø–æ–∫–∞–∂–∏ –≤—Ç–æ—Ä—É—é –∫–∞—Ä—Ç–∏–Ω–∫—É', '–∫–∞—Ä—Ç–∏–Ω–∫–∞ –¥–≤–∞', '—Å–ª–∞–π–¥ 2', '–≤—Ç–æ—Ä–æ–π']
            },
            'media_img_3': {
                'func': lambda: self.cmd_send_media("3", "off"),
                'phrases': ['–ø–æ–∫–∞–∂–∏ —Ç—Ä–µ—Ç—å—é –∫–∞—Ä—Ç–∏–Ω–∫—É', '–∫–∞—Ä—Ç–∏–Ω–∫–∞ —Ç—Ä–∏', '—Å–ª–∞–π–¥ 3', '—Ç—Ä–µ—Ç–∏–π']
            },
            'media_music_on': {
                'func': lambda: self.cmd_send_media("1", "on"),
                'phrases': ['–≤–∫–ª—é—á–∏ –º—É–∑—ã–∫—É', '–∏–≥—Ä–∞–π –º—É–∑—ã–∫—É', '–º—É–∑—ã–∫–∞']
            },
            'volume_up': {
                'func': lambda: self.cmd_volume("up"),
                'phrases': ['–≥—Ä–æ–º—á–µ', '—Å–¥–µ–ª–∞–π –≥—Ä–æ–º—á–µ', '–ø–æ–¥–Ω–∏–º–∏ –∑–≤—É–∫', '—É–≤–µ–ª–∏—á—å –≥—Ä–æ–º–∫–æ—Å—Ç—å', '–¥–æ–±–∞–≤—å –∑–≤—É–∫']
            },
            'volume_down': {
                'func': lambda: self.cmd_volume("down"),
                'phrases': ['—Ç–∏—à–µ', '—Å–¥–µ–ª–∞–π —Ç–∏—à–µ', '—É–±–∞–≤—å –∑–≤—É–∫', '—É–º–µ–Ω—å—à–∏ –≥—Ä–æ–º–∫–æ—Å—Ç—å']
            },
            'volume_max': {
                'func': lambda: self.cmd_volume("max"),
                'phrases': ['–º–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –≥—Ä–æ–º–∫–æ—Å—Ç—å', '–∑–≤—É–∫ –Ω–∞ –º–∞–∫—Å–∏–º—É–º', '–ø–æ–ª–Ω–∞—è –≥—Ä–æ–º–∫–æ—Å—Ç—å']
            },
            'volume_mute': {
                'func': lambda: self.cmd_volume("mute"),
                'phrases': ['–≤—ã–∫–ª—é—á–∏ –∑–≤—É–∫', '–±–µ–∑ –∑–≤—É–∫–∞', '—Ç–∏—à–∏–Ω–∞']
            }
        }
    
    def cmd_send_media(self, img="1", mus="off"):
        payload = {"type": "static_image", "image_number": img, "music_data": mus}
        try: requests.post(MEDIA_PLAYER_URL, json=payload, timeout=0.1)
        except: pass
        return True

    def cmd_volume(self, action):
        print(f"üîä –ì–†–û–ú–ö–û–°–¢–¨: {action}")
        payload = {"type": "volume", "action": action}
        try: requests.post(MEDIA_PLAYER_URL, json=payload, timeout=0.1)
        except: pass
        return True

    def cmd_stop(self):
        self.running = False
        return True

    def run(self):
        p = pyaudio.PyAudio()
        stream = p.open(format=pyaudio.paInt16, channels=1, rate=16000, input=True, frames_per_buffer=4000)
        stream.start_stream()
        print("\nüé§ –ì–û–í–û–†–ò–¢–ï... (–ö–æ–º–∞–Ω–¥—ã: '–ì—Ä–æ–º—á–µ', '–¢–∏—à–µ', '–°—Ç–æ–ø')")

        while self.running:
            data = stream.read(4000, exception_on_overflow=False)
            if self.recognizer.AcceptWaveform(data):
                res = json.loads(self.recognizer.Result())
                text = res.get('text', '')
                if text:
                    print(f"üó£Ô∏è  '{text}'")
                    match = self.analyzer.analyze(text)
                    if match:
                        print(f"üöÄ {match['intent']}")
                        self.intents[match['intent']]['func']()
        
        stream.stop_stream()
        stream.close()
        p.terminate()

if __name__ == "__main__":
    InfoAssistant().run()